---
title: "2 - Introducing the t-distribution"
output: html_notebook
---


```{r}
library(tidyverse)
library(ggplot2)
library(infer)     # bootstrap
library(openintro)

acs12 <- readRDS("./datasets/acs12.rds")
```




# t-distribution

![t shape](./img/shape_of_t_dist.png)

## When to t? 

Which of the following describes best why we might need to use the t-distribution for inference?:

- population distribution is not known

- **population standard deviation is unknown**

- sample is not random

- sample is not representative of the population


## Probabilities under the t-distribution

We can use the pt() function to find probabilities under the t-distribution. For a given **cutoff value** _q_ and a given degrees of freedom _df, pt(q, df)_ gives us the probability under the t-distribution with _df_ degrees of freedom for values of _t_ less than _q_. In other words,  $P(t_{df} < T)$ = pt(q = T, df).


Find the probability under the t-distribution with 10 degrees of freedom below $T=3$.
```{r}
# P(T < 3) for df = 10
(x <- pt(3, df = 10))
```

```{r}
# P(T > 3) for df = 10
(y <- 1 - x)
```

```{r}
# P(T > 3) for df = 100
(z <- 1 - pt(3, df = 100))
```

```{r}
# Comparison
y == z
y > z
y < z
```



## Cutoffs under the t-distribution

We can use the qt() function to find cutoffs under the t-distribution. For a given probability p and a given degrees of freedom df, qt(p, df) gives us the cutoff value for the t-distribution with df degrees of freedom for which the probability under the curve is p. In other words, if $P(t_{df}<T=p)$, then $T$ =  qt(p, df). For example, if  corresponds to the 95th percentile of a distribution, . The "middle 95%" means from p = 0.025 to p = 0.975.

```{r}
# 95th percentile for df = 10
(x <- qt(0.95, df = 10))
```

```{r}
# Upper bound of middle 95th percent for df = 10
(y <- qt(0.975, df = 10))
```

```{r}
# Upper bound of middle 95th percent for df = 100
(z <- qt(0.975, df = 100))
```

```{r}
# Comparison
y == z
y > z
y < z
```


# Estimating a mean with a t-interval

![](./img/central_limit_theorem.png)

![](./img/clt_conditions.png)


## Average conmute time of Americans

Each year since 2005, the US Census Bureau surveys about 3.5 million households with The American Community Survey (ACS). Data collected from the ACS have been crucial in government and policy decisions, helping to determine the allocation of federal and state funds each year. Data from the 2012 ACS is available in the acs12 dataset.

When given one argument, t.test() tests whether the population mean of its input is different than 0. That is $H_0 : \mu_{diff} = 0$ and $H_A : \mu_{diff} \neq 0$. It also provides a 95% confidence interval.


```{r}
# Filter for employed respondents
acs12_emp <- acs12 %>%
  filter(employment == "employed")

# Construct 95% CI for avg time_to_work
t.test(acs12_emp$time_to_work)
```
And now you now how long Americans need to travel to work, on average, with 95% confidence.

## Average number of hours worked

Full-time employment is employment in which a person works a minimum number of hours defined as such by his/her employer. Companies in the United States commonly require 40 hours per week to be considered a full time employee. We will use data from the American Community Survey to estimate the number of hours Americans work.

Use the acs12_emp dataset you created earlier; it's already loaded for you.

```{r}
# Run a t-test on hrs_work and look at the CI
t.test(acs12_emp$hrs_work)
```

For this analysis, it would have made more sense to use a subset excluding part time workers.


# t-interval for paired data

## Understanding confidence intervals

textbooks is available in your workspace. Experiment with t-tests on diff at different confidence levels and on different size subsets of the data.


```{r}
textbooks
```

- As the sample size increases, the margin of error of the interval increases as well.

```{r}
t.test(sample(textbooks$diff, 10), conf.level = .90)

t.test(sample(textbooks$diff, 10), conf.level = .95)

t.test(sample(textbooks$diff, 10), conf.level = .99)
```


```{r}
t.test(textbooks$diff, conf.level = .90)

t.test(textbooks$diff, conf.level = .95)

t.test(textbooks$diff, conf.level = .99)
```

Which of the following **IS FALSE** about confidence intervals when all else is held constant?

- As the confidence level increases, the margin of error of the interval increases as well. -> TRUE

- As the confidence level increases, the width of the interval increases as well. -> TRUE, Correct! A larger sample size will decrease the margin of error of the interval.

- As the sample size increases, the margin of error of the interval increases as well. -> FALSE

- As the sample size increases, the precision of the interval increases as well. -> TRUE


# Testing a mean with a t-test

## Estimating the median difference in textbook prices

Suppose instead of the mean, we want to estimate the median difference in prices of the same textbook at the UCLA bookstore and on Amazon. You can't do this using a t-test, as the Central Limit Theorem only talks about means, not medians. You'll use an infer pipeline to estimate the median.

```{r}
textdiff_med_ci <- textbooks %>%
  specify(response = diff) %>%
  generate(reps = 15000, type = "bootstrap") %>%
  calculate(stat = "median")
```

```{r}
# Calculate the 95% CI via percentile method
textdiff_med_ci %>%
  summarize(
    l = quantile(stat, 0.025),
    u = quantile(stat, 0.975)
  )
```

## Test for a difference in median tests scores

The High School and Beyond survey is conducted on high school seniors by the National Center of Education Statistics. We randomly sampled 200 observations from this survey, and these data are in the hsb2 data frame (which is already loaded for you). Among other variables, this data frame contains scores on math and science scores of each sampled student.

```{r}
n_replicates <- 15000

hsb2 <- hsb2 %>%
  mutate(diff = math - science)

hsb2 %>% 
  ggplot(aes(x = diff)) + 
  geom_histogram() + ggtitle("math - science")
```


```{r}
scorediff_med_ht <- hsb2 %>%
  specify(response = diff) %>%
  hypothesize(null = "point", med = 0) %>% 
  generate(reps = n_replicates, type = "bootstrap") %>% 
  calculate(stat = "median")
```

```{r}
scorediff_med_ht %>% visualize()
```

```{r}
# Calculate observed median of differences
scorediff_med_obs <- hsb2 %>%
  summarize(median_diff = median(diff)) %>%
  pull()

scorediff_med_obs
```

```{r}
# Calculate two-sided p-value
scorediff_med_ht %>%
  filter(stat >= scorediff_med_obs) %>%
  summarize(
    one_sided_p_val = n() / n_replicates,
    two_sided_p_val = 2 * one_sided_p_val
  )
```

We fail to reyect the null hypothesis, there is no significative difference between math and science grades.

## Interpret the p-value

In the previous exercise, you conducted a hypothesis test to evaluate whether the median scores on math and science exams are different. The observed median difference and p-value that you calculated are in your workspace as scorediff_med_obs and scorediff_p_value.

Which of the following is the correct definition of the p-value of this hypothesis test?

- The probability of getting a random sample of 200 high school students where the median difference between their math and science test scores is at least 1, if in fact there is no difference between the median math and science scores.

Correct! A p-value is the probability of observing data at least as extreme as yours, given the null hypothesis is true.
